{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanisha1011/BEFL/blob/main/Work1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZvqPCkq9dyq",
        "outputId": "65050dd9-6e5a-4061-f4c6-3f8be8def29d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import json\n",
        "from time import time\n",
        "\n",
        "# Example dataset\n",
        "class ExampleDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "# Simple neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "def train_local_model(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for data, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model.state_dict(), loss.item()\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in test_loader:\n",
        "            outputs = model(data)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def federated_aggregation(global_model, local_models):\n",
        "    global_dict = global_model.state_dict()\n",
        "    for k in global_dict.keys():\n",
        "        global_dict[k] = torch.stack([local_models[i][k].float() for i in range(len(local_models))], 0).mean(0)\n",
        "    global_model.load_state_dict(global_dict)\n",
        "    return global_model\n",
        "\n",
        "class Blockchain:\n",
        "    def __init__(self):\n",
        "        self.chain = []\n",
        "        self.current_transactions = []\n",
        "        self.new_block(previous_hash='1', proof=100)\n",
        "\n",
        "    def new_block(self, proof, previous_hash=None):\n",
        "        block = {\n",
        "            'index': len(self.chain) + 1,\n",
        "            'timestamp': time(),\n",
        "            'transactions': self.current_transactions,\n",
        "            'proof': proof,\n",
        "            'previous_hash': previous_hash or self.hash(self.chain[-1]),\n",
        "        }\n",
        "        self.current_transactions = []\n",
        "        self.chain.append(block)\n",
        "        return block\n",
        "\n",
        "    def new_transaction(self, client_id, model_state):\n",
        "        self.current_transactions.append({\n",
        "            'client_id': client_id,\n",
        "            'model_state': model_state,\n",
        "        })\n",
        "        return self.last_block['index'] + 1\n",
        "\n",
        "    @staticmethod\n",
        "    def hash(block):\n",
        "        block_string = json.dumps(block, sort_keys=True).encode()\n",
        "        return hashlib.sha256(block_string).hexdigest()\n",
        "\n",
        "    @property\n",
        "    def last_block(self):\n",
        "        return self.chain[-1]\n",
        "\n",
        "    def proof_of_work(self, last_proof):\n",
        "        proof = 0\n",
        "        while self.valid_proof(last_proof, proof) is False:\n",
        "            proof += 1\n",
        "        return proof\n",
        "\n",
        "    @staticmethod\n",
        "    def valid_proof(last_proof, proof):\n",
        "        guess = f'{last_proof}{proof}'.encode()\n",
        "        guess_hash = hashlib.sha256(guess).hexdigest()\n",
        "        return guess_hash[:4] == \"0000\"\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "data = np.random.rand(1000, 2)\n",
        "labels = (data[:, 0] + data[:, 1] > 1).astype(float).reshape(-1, 1)\n",
        "\n",
        "# Split data into training and testing\n",
        "train_data, test_data = data[:800], data[800:]\n",
        "train_labels, test_labels = labels[:800], labels[800:]\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataset = ExampleDataset(torch.tensor(train_data, dtype=torch.float32), torch.tensor(train_labels, dtype=torch.float32))\n",
        "test_dataset = ExampleDataset(torch.tensor(test_data, dtype=torch.float32), torch.tensor(test_labels, dtype=torch.float32))\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize global model\n",
        "global_model = SimpleNN()\n",
        "criterion = nn.BCELoss()\n",
        "initial_lr = 0.01\n",
        "\n",
        "# Initialize blockchain\n",
        "blockchain = Blockchain()\n",
        "\n",
        "# Federated learning simulation with blockchain\n",
        "num_rounds = 25\n",
        "num_clients = 10\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    local_models = []\n",
        "    for client in range(num_clients):\n",
        "        local_model = SimpleNN()\n",
        "        local_model.load_state_dict(global_model.state_dict())\n",
        "        optimizer = optim.SGD(local_model.parameters(), lr=initial_lr)\n",
        "        local_state, local_loss = train_local_model(local_model, train_loader, criterion, optimizer)\n",
        "\n",
        "        # Serialize model state to JSON compatible format\n",
        "        model_state_dict = {k: v.tolist() for k, v in local_state.items()}\n",
        "\n",
        "        # Record the model update on the blockchain\n",
        "        blockchain.new_transaction(client_id=client, model_state=model_state_dict)\n",
        "\n",
        "        local_models.append(local_state)\n",
        "\n",
        "    # Perform federated aggregation\n",
        "    global_model = federated_aggregation(global_model, local_models)\n",
        "\n",
        "    # Create a new block in the blockchain after aggregation\n",
        "    last_block = blockchain.last_block\n",
        "    last_proof = last_block['proof']\n",
        "    proof = blockchain.proof_of_work(last_proof)\n",
        "    previous_hash = blockchain.hash(last_block)\n",
        "    blockchain.new_block(proof, previous_hash)\n",
        "\n",
        "    # Evaluate the global model\n",
        "    accuracy = evaluate_model(global_model, test_loader)\n",
        "    print(f\"Round {round + 1}: Global Model Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Display final accuracy\n",
        "final_accuracy = evaluate_model(global_model, test_loader)\n",
        "print(f\"Final Global Model Accuracy: {final_accuracy:.2f}%\")\n",
        "\n",
        "# Display blockchain\n",
        "for block in blockchain.chain:\n",
        "    print(f\"Block {block['index']}: {block}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "global_model_accuracies = []\n",
        "global_model_losses = []\n",
        "avg_local_losses = []\n",
        "num_transactions = []\n",
        "blockchain_size = []\n",
        "\n",
        "# Federated learning simulation with blockchain\n",
        "num_rounds = 25\n",
        "num_clients = 10\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    local_models = []\n",
        "    local_losses = []\n",
        "    for client in range(num_clients):\n",
        "        local_model = SimpleNN()\n",
        "        local_model.load_state_dict(global_model.state_dict())\n",
        "        optimizer = optim.SGD(local_model.parameters(), lr=initial_lr)\n",
        "        local_state, local_loss = train_local_model(local_model, train_loader, criterion, optimizer)\n",
        "\n",
        "        local_models.append(local_state)\n",
        "        local_losses.append(local_loss)\n",
        "\n",
        "        blockchain.new_transaction(client_id=client, model_state={k: v.tolist() for k, v in local_state.items()})\n",
        "\n",
        "    # Compute metrics for the round\n",
        "    global_model_accuracies.append(evaluate_model(global_model, test_loader))\n",
        "    global_model_losses.append(criterion(global_model(torch.tensor(test_data, dtype=torch.float32)), torch.tensor(test_labels, dtype=torch.float32)).item())\n",
        "    avg_local_losses.append(np.mean(local_losses))\n",
        "    num_transactions.append(len(blockchain.current_transactions))\n",
        "    blockchain_size.append(len(blockchain.chain))\n",
        "\n",
        "    # Perform federated aggregation\n",
        "    global_model = federated_aggregation(global_model, local_models)\n",
        "\n",
        "    # Create a new block in the blockchain after aggregation\n",
        "    last_block = blockchain.last_block\n",
        "    proof = blockchain.proof_of_work(last_block['proof'])\n",
        "    previous_hash = blockchain.hash(last_block)\n",
        "    blockchain.new_block(proof, previous_hash)\n",
        "\n",
        "    # Print current round's metrics\n",
        "    print(f\"Round {round + 1}: Global Model Accuracy: {global_model_accuracies[-1]:.2f}%, Global Model Loss: {global_model_losses[-1]:.4f}, Average Local Loss: {avg_local_losses[-1]:.4f}\")\n",
        "\n",
        "# Display final accuracy\n",
        "final_accuracy = evaluate_model(global_model, test_loader)\n",
        "print(f\"Final Global Model Accuracy: {final_accuracy:.2f}%\")\n",
        "\n",
        "# Display blockchain\n",
        "for block in blockchain.chain:\n",
        "    print(f\"Block {block['index']}: {block}\")\n",
        "\n",
        "# Plotting the metrics\n",
        "rounds = range(1, num_rounds + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Plot Global Model Accuracy\n",
        "plt.subplot(3, 2, 1)\n",
        "plt.plot(rounds, global_model_accuracies, marker='o')\n",
        "plt.title('Global Model Accuracy')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "\n",
        "# Plot Global Model Loss\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.plot(rounds, global_model_losses, marker='o')\n",
        "plt.title('Global Model Loss')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Plot Average Local Loss\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.plot(rounds, avg_local_losses, marker='o')\n",
        "plt.title('Average Local Model Loss')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Plot Number of Transactions per Round\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.plot(rounds, num_transactions, marker='o')\n",
        "plt.title('Number of Transactions')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Number of Transactions')\n",
        "\n",
        "# Plot Blockchain Size (Number of Blocks)\n",
        "plt.subplot(3, 2, 5)\n",
        "plt.plot(rounds, blockchain_size, marker='o')\n",
        "plt.title('Blockchain Size')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Number of Blocks')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdU2bt+9RJcj6dL7pFM4oY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}